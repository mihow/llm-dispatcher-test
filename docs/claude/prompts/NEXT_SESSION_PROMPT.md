# Next Session: Continue Ham Radio Voice Assistant Implementation

## Current Status

**PR #1**: https://github.com/mihow/llm-dispatcher-test/pull/1
- Branch: `feature/phase1-marco-polo`
- Base: `main`

### ‚úÖ Completed (Steps 1-2)

**Step 1: Audio Capture** (commit 2df9ba2)
- `radio_assistant/audio_interface.py` - Platform-agnostic audio I/O
- 20 unit tests + 13 integration tests
- Test script: `scripts/test_audio_capture.py`

**Step 2: VAD Detection** (commit d1bbf96)
- `radio_assistant/vad_detector.py` - Silero VAD integration
- 20 unit tests + 15 integration tests
- Test audio generation: `scripts/generate_vad_test_audio.py`
- Test script: `scripts/test_vad.py`

### ‚ö†Ô∏è Issues to Fix

**GitHub Actions tests are failing** - need to debug CI pipeline:
1. Check test output in PR #1
2. Fix any dependency installation issues
3. Update `.github/workflows/test.yml` if needed
4. Ensure tests pass in CI environment

Likely issues:
- Missing system dependencies (libportaudio2, libsndfile1)
- Module import errors in CI
- Test audio file paths

### üìã Next Steps (Steps 3-7)

**Step 3: Whisper Transcription** (next priority)
- Implement `TranscriptionEngine` class using faster-whisper
- Create test audio files with ground truth transcriptions
- Test files needed (per plan):
  - `wsjj659_clear.wav` + transcript.txt
  - `wsjj659_phonetic.wav` + transcript.txt
  - `wsjj659_noisy.wav` + transcript.txt
  - `wsjj659_rapid.wav` + transcript.txt
  - `other_callsign.wav` + transcript.txt
- Unit tests + integration tests + benchmarks
- Validate transcription accuracy (>95% for callsign)
- Measure performance (<2s transcription time)

**Step 4: Callsign Detection**
- Implement `CallsignDetector` class
- Pattern matching for "WSJJ659" (plain, phonetic, variations)
- Comprehensive test cases (see plan lines 340-365)
- 100% code coverage required

**Step 5: PTT/VOX Control**
- Implement `PTTController` class
- VOX padding for clean audio transmission
- Pre-generated response audio
- Manual testing procedures in TESTING.md

**Step 6: End-to-End Pipeline**
- Main `RadioAssistant` application
- E2E test scenarios
- Mock radio interface for testing
- Complete pipeline validation

**Step 7: Hardware Validation**
- Raspberry Pi testing documentation
- Performance benchmarks
- Manual test procedures

## Environment Setup

**Python Environment:**
- Conda env: `cuda12` (`/home/michael/miniforge3/envs/cuda12`)
- Package manager: `uv` for dependencies
- Python: 3.12.9

**Key Dependencies:**
```bash
/home/michael/miniforge3/envs/cuda12/bin/pip install \
  sounddevice numpy librosa scipy \
  torch silero-vad \
  pydantic typer pyyaml loguru \
  pytest pytest-cov pytest-mock soundfile
```

**For Step 3, also install:**
```bash
/home/michael/miniforge3/envs/cuda12/bin/pip install faster-whisper
```

## Project Structure

```
/home/michael/Projects/Radio/llm-dispatcher-test/
‚îú‚îÄ‚îÄ radio_assistant/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ audio_interface.py       ‚úÖ Complete
‚îÇ   ‚îú‚îÄ‚îÄ vad_detector.py          ‚úÖ Complete
‚îÇ   ‚îú‚îÄ‚îÄ transcription_engine.py  ‚è≥ Next (Step 3)
‚îÇ   ‚îú‚îÄ‚îÄ callsign_detector.py     ‚è≥ Step 4
‚îÇ   ‚îú‚îÄ‚îÄ ptt_controller.py        ‚è≥ Step 5
‚îÇ   ‚îî‚îÄ‚îÄ main.py                  ‚è≥ Step 6
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ test_audio_capture.py
‚îÇ   ‚îú‚îÄ‚îÄ generate_vad_test_audio.py
‚îÇ   ‚îú‚îÄ‚îÄ test_vad.py
‚îÇ   ‚îî‚îÄ‚îÄ test_transcription.py    ‚è≥ Create for Step 3
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_audio_interface.py      (20 tests)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_vad_detector.py         (20 tests)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_transcription_engine.py ‚è≥ Create
‚îÇ   ‚îú‚îÄ‚îÄ integration/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_audio_capture.py        (13 tests)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_vad_pipeline.py         (15 tests)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_transcription_accuracy.py ‚è≥ Create
‚îÇ   ‚îú‚îÄ‚îÄ benchmarks/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_transcription_performance.py ‚è≥ Create
‚îÇ   ‚îî‚îÄ‚îÄ audio/
‚îÇ       ‚îú‚îÄ‚îÄ vad/                 ‚úÖ 7 files generated
‚îÇ       ‚îú‚îÄ‚îÄ transcription/       ‚è≥ Create for Step 3
‚îÇ       ‚îú‚îÄ‚îÄ responses/           ‚è≥ Create for Step 5
‚îÇ       ‚îî‚îÄ‚îÄ e2e/                 ‚è≥ Create for Step 6
‚îú‚îÄ‚îÄ docs/claude/planning/
‚îÇ   ‚îî‚îÄ‚îÄ INITIAL_IMPLEMENTATION_PLAN.md (full spec)
‚îú‚îÄ‚îÄ .github/workflows/
‚îÇ   ‚îî‚îÄ‚îÄ test.yml                 ‚ö†Ô∏è Needs fixes
‚îú‚îÄ‚îÄ pyproject.toml
‚îú‚îÄ‚îÄ config.example.yaml
‚îî‚îÄ‚îÄ README.md

Context: 107K/200K tokens used (53%)
```

## Important Guidelines

From `CLAUDE.md`:

1. **Cost Optimization**
   - Keep context under 40% when possible (currently at 53%)
   - Use command-line tools over reading files
   - Prefer language servers over grep when available

2. **Type Annotations** (Python 3.10+ style)
   ```python
   # ‚úÖ CORRECT
   def process(items: list[str], config: dict[str, int] | None = None) -> tuple[str, int]:
       ...

   # ‚ùå WRONG - old style
   from typing import List, Optional, Dict
   def process(items: List[str], config: Optional[Dict[str, int]] = None):
       ...
   ```

3. **Commit Strategy**
   - Commit often with focused changes
   - Use `git add -p` for interactive staging
   - Each step gets its own checkpoint commit

## Immediate Actions for Next Session

1. **Fix CI Tests**
   ```bash
   # Check PR test failures
   gh pr view 1 --web

   # Run tests locally to verify
   /home/michael/miniforge3/envs/cuda12/bin/python -m pytest tests/ -v

   # Fix any issues in .github/workflows/test.yml
   ```

2. **Start Step 3: Transcription Engine**
   ```bash
   # Install faster-whisper
   /home/michael/miniforge3/envs/cuda12/bin/pip install faster-whisper

   # Create TranscriptionEngine class
   # - See plan lines 242-274 for API spec
   # - Use faster-whisper library
   # - Support base/small/medium models
   # - Return structured TranscriptionResult

   # Generate test audio with known transcripts
   # Create script to synthesize or record test phrases

   # Implement comprehensive tests
   # - Unit tests with mocks
   # - Integration tests with real audio
   # - Benchmarks for performance (<2s target)
   ```

3. **Update TODO List**
   ```bash
   # Mark CI fixes as in-progress
   # Track Step 3 sub-tasks
   ```

## Reference Files

- Implementation Plan: `docs/claude/planning/INITIAL_IMPLEMENTATION_PLAN.md`
- Development Guidelines: `CLAUDE.md`
- Current PR: https://github.com/mihow/llm-dispatcher-test/pull/1
- Test Workflow: `.github/workflows/test.yml`

## Success Criteria for Next Session

- [ ] All CI tests passing in PR #1
- [ ] Step 3: TranscriptionEngine implemented
- [ ] Transcription tests created and passing
- [ ] Performance benchmarks show <2s transcription time
- [ ] Commit Step 3 checkpoint
- [ ] Update PR with Step 3 progress

## Commands Reference

```bash
# Activate environment
# (conda env cuda12 is active by default)

# Run tests
/home/michael/miniforge3/envs/cuda12/bin/python -m pytest tests/unit/ -v
/home/michael/miniforge3/envs/cuda12/bin/python -m pytest tests/integration/ -v

# Run with coverage
/home/michael/miniforge3/envs/cuda12/bin/python -m pytest tests/ --cov=radio_assistant --cov-report=term

# Install dependencies
/home/michael/miniforge3/envs/cuda12/bin/pip install <package>

# Commit checkpoint
git add -A
git commit -m "feat: Implement Step 3 - Transcription Engine (checkpoint/transcription)"
git push origin feature/phase1-marco-polo
```

---

**Goal**: Complete Phase 1 "Marco Polo" test - validate audio pipeline before adding LLM complexity.

**Current Branch**: `feature/phase1-marco-polo`

**Start Here**: Fix CI tests, then implement Step 3 (Transcription Engine)
